nohup python train_model.py --epoches 1000 --batch_size=256 2>&1 >logs/train.log &
